---
title: "Life, Learning & LLMs"
subtitle: "How AI is changing the landscape of learning and coding"
tags: [AI, Learning, Coding, LLMs]
date: 2024-10-23
author: Siddharth
layout: post
math: false
giscus_comments: true
share: true
---


# Introduction

I recently started the third year of my CS degree and realized something significant: I am part of the first generation of college students who have access to a whole new paradigm of learning with AI. Up to this point, everything I heard about AI was theoretical. The most significant anecdote in my memory about AI stems from my 6th or 7th-grade English book, an Isaac Asimov story [[1]](#1).

Returning to the point, I wanted to talk about how AI has subtly changed my daily life. To be clear, I'm not claiming it has revolutionized everything, but I've noticed some changes in my habits—some for better, some for worse.

Two of the most significant use cases for AI in my life as a college student are writing/learning and coding. There are others too, but these have had a profound impact on me as a person.

# Daily Writing with LLMs

When I started using Language Learning Models (LLMs), I was surprised not by their ability to write but by their ability to adapt to different writing styles. This opened many doors—some good, like no longer having to spend too much time writing applications or emails for mundane tasks, and some bad, like easily slacking through my creative classes at college. I no longer found writing technical essays or homework that required hours of research to be tedious tasks since AI could generate them for me within seconds. Although sometimes it got me into trouble with cited sources, I soon learned that tweaking my prompts could help with that. But the million-dollar question is:

## Did it make my writing worse or better?

In high school, we were often asked to write answers to literature questions spontaneously. This exercise was done so frequently that I feel it genuinely improved my ability to articulate thoughts. Certainly, I might not be a great writer, but I can at least express myself well. (It might be obvious at this point, but English is not my first language, though I've been learning it for the past 15 years, so I should be good by now.) So, I can't say it has degraded my ability to write well, but it has certainly helped me express myself better (which, as you'll see, isn't necessarily the case for coding).

AI has certainly made me lazier. When I receive an email or write something, I jot down a rough reply in Notepad and ask the AI to improve it later. After some prompting, I get satisfactory results. For example, take this blog—I'm pretty sure that before publishing, I'll pass it through AI to improve the tone and correct grammatical errors. Wait! Now that I think about it, I'll also attach my manually written draft so you can compare my writing style with the published one [[2]](#2). It's certainly not a perfect metric, but it's something!

At the same time, it has various advantages for me. Now, when I apply for internships, I no longer have to write my Statements of Purpose (SOPs) from scratch multiple times. I can just **prompt-bomb** [[3]](#3) it with all the info about the internship, my goals, my resume, and it whips up a great first draft. From there, with a bit of prompting, things become a lot easier. What would have taken me days to write can be completed in a matter of hours. So that's definitely going into the plus column.

Now, coming to the second and most controversial use case (sometimes it keeps me up at night!):

# Coding with LLMs

If you're reading this blog, there's a great chance you've used AI for coding. Before we dive into this, a caution: I used to be a big believer in AI boosting your learning—I still am—but for coding purposes, I'm not so sure anymore. Before we go any further, we need to clarify something, including "What does being good at coding mean?" For the purpose of this blog (and for me personally), it means being able to convert your thoughts and ideas into a practical software application with a reasonable understanding of its workings. Of course, you can disagree with me—I hope you do :)

## LLM Learning Curse

Now that we've defined it, let's talk about how AI has shaped me. When I entered college, I was given the same advice that millions of freshmen receive every year: learn the theory, practice, implement, and if you get stuck, "Google it, use Stack Overflow, refer to documentation, etc." But as soon as AI arrived (ChatGPT in November 2022), things changed a lot. Unlike math, AI was good at coding (it could generate code for whatever I wanted it to do), and suddenly, most of my tasks were being outsourced to it. Mind you, it's not that I wasn't doing or trying my homework, but when I got stuck or didn't know how to start, I framed the problem to AI, and voilà—a working answer was right in front of me.

While on the surface it might not seem like a huge problem, let's take an example: my OOP course. I read and implemented all the examples from my course book, but when someone asked me to write an example problem from scratch, I was blank. And here's where things diverge from traditional learning. Without AI, your option was to Google it and hope to find the exact answer or go through the text again to gain a better understanding. But with AI, you don't need to do all this; just give it the problem or your thoughts, and it customizes the answer to your needs. I was able to understand it, so it felt like I satisfied all the criteria: I could convert my thoughts to code, I had a reasonable understanding of it, and it worked! So, I thought I was getting good at coding.

At first glance, this might seem obvious, and you might be thinking, "You're not actually coding; you're just using AI." But hear me out—it's not that simple. It's not like I didn't understand the concept; I knew when to use inheritance; I just wasn't able to translate it into code. I used a tool to do so. I told it what I wanted to do; it did it for me; I read it, understood it, and implemented it. While this gave me some sense of confidence and understanding, it took something very important from me, which I realized very late: my knowledge of what not to do. In traditional learning, you go through lots of sites, lots of trial and error, and in the process, you learn what not to do. This is something I missed out on with AI.

## The Good Part of Coding with AI

It's not all gloomy and sad. I mean, at this point, it's fairly obvious I should stop using AI for coding; it would solve all my problems. But consider the benefits it brought me. To give context, I'm someone who easily gets intimidated by things, especially in tech. If I read something once or twice and didn't understand, I would think I lacked the prerequisite knowledge (which is only somewhat true in CS—that's a topic for another day). This mindset would have stopped me from learning a lot of things, but with AI, the possibilities were limitless. I wanted to learn about AI in my first semester, but seeing all the math terms would have deterred me. But with LLMs, I was able to perform MNIST classification in Python with only a high-level understanding of things. Sure, this might not seem like a big deal, but think from the perspective of an 18-year-old who recently learned loops in Python—this was huge.

But if you notice, I missed a step in becoming good at coding: I didn't have a reasonable understanding. To overcome this, I found a loophole. I started learning about libraries like scikit-learn, PyTorch, and began looking into the APIs being used, and soon enough, I started to understand what was happening in the code. So, in a way, I started doing reverse learning. I first converted my idea into code and then learned how and what was happening in my code. This does satisfy the criteria of "reasonable understanding," and soon enough, I was able to do all kinds of things. I was able to run before I could walk well, but I didn't realize I was using a walker [[4]](#4) to run for a long time. I call it the "Curse of AI": **I can understand code, but I can't write it.**

It enables me to do a lot of things, like fine-tuning a TTS model without having to learn what fine-tuning is. With AI, I felt the sky was the limit (note: with AI, I use docs and other methods, but instead of reading them myself, I **prompt-bomb** [[3]](#3) them into AI to solve the problem, and most of the time, it works). So now I'm in this weird place where I can code a lot of things with reasonable understanding and at the same time, I cannot do this at all.

# Solution?

When I look at top developers and the OG anime-profile-picture developers, I find myself strangely disconnected and wonder, would I ever be able to do that? Sometimes I think as long as I use AI, I will always have this imposter syndrome. One obvious solution would be to stop using AI completely for coding, but that feels like trying to put a secret back into the bag.

Recently, Andrej Karpathy tweeted this

{% twitter https://twitter.com/karpathy/status/1827143768459637073 %}

, and it made me think that now this is the new normal. It's just that I never got the chance to explore the "old" techniques.

The truth is I am still looking for the **middle ground.**


This is my first time writing a blog

. Please leave feedback, thoughts, and criticism—I'd love to hear from you on [X/Twitter](https://x.com/Sid_899).

---

### References

1. [The Fun They Had](https://en.wikipedia.org/wiki/The_Fun_They_Had)  
2. [Original Draft](https://www.notion.so/Original-Draft-128a0da4ab5080148c7cf337b788a530?pvs=21)  
3. I have coined this term, hoping it catches on!  
4. [Baby Walker](https://en.wikipedia.org/wiki/Baby_walker)  

---