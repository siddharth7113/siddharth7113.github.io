<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://siddharth7113.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://siddharth7113.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-09-13T19:54:11+00:00</updated><id>https://siddharth7113.github.io/feed.xml</id><title type="html">Siddharth</title><subtitle>A simple portfolio for Siddharth, showcasing projects, achievements, and academic work. </subtitle><entry><title type="html">Why seek the Unknown</title><link href="https://siddharth7113.github.io/blog/2025/why-seek-unknown/" rel="alternate" type="text/html" title="Why seek the Unknown"/><published>2025-09-13T00:00:00+00:00</published><updated>2025-09-13T00:00:00+00:00</updated><id>https://siddharth7113.github.io/blog/2025/why-seek-unknown</id><content type="html" xml:base="https://siddharth7113.github.io/blog/2025/why-seek-unknown/"><![CDATA[<p>I don’t post often, but after rambling in my editor and fresh off a rewatch of <em>Interstellar</em>, I felt compelled to share this. This isn’t a film review. It’s a reflection on a question that got stuck in my head as the credits rolled:</p> <h2 id="why-do-people-choose-to-seek-the-unknown-when-they-already-have-something-to-hold-on-to"><strong>Why do people choose to seek the unknown when they already have something to hold on to?</strong></h2> <p>There are many possible answers- love, glory, curiosity, fear, empathy, loneliness<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>. Maybe that impulse to step off the map is precisely why <em>Homo sapiens</em> survived and built so much in so little time.</p> <p>There’s a lot of noise online about “researchers vs. engineers”<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>, but beneath we’re still the same primates with oddly shaped tools, drawn toward black boxes we don’t yet understand. Being in AI, I can’t resist the analogy: sometimes we choose to <strong>explore</strong> instead of <strong>exploit</strong>, a little DQN in the bloodstream.</p> <h2 id="local-minima-and-the-itch-to-look-up">Local minima and the itch to look up</h2> <p>We’re all protagonists in our own stories, and it’s easy to get trapped in a local minima(sorry for the ML reference) and forget the direction we meant to move. Rationally, exploration is a terrible bet: the probability of failure often dwarfs the chance of success. Most of us <em>will</em> fail. And yet, some still choose to look beyond.</p> <p>It’s easy to romanticize the leap. What’s harder is <strong>not stopping</strong> once the loneliness sets in, when you miss love, when you are just a lost face in crowd. That’s where the journey ends for most of us. People say, “In the real world, other things matter more.” The irony is that much of what we call “real” is just the majority’s interpretation. The objective world is there either way; our choice is whether to exploit what we’ve got or explore what we might find. Most will exploit and that’s fine. Societies need stability. But the few who can’t ignore the itch will pull for the rest of us.</p> <h2 id="on-real-intelligence">On “real” intelligence</h2> <p>Right now, there’s an AI race and lots of talk about AGI on the horizon. But who gets to certify what counts as “real” intelligence? Perhaps we’re just searching for systems that sometimes choose to explore,driven by math, emotion, or something that looks like both. That blend is hard to design and harder to prove. I think we’ll eventually build systems that earn the label “real” intelligence not because they predict the next token, but because they <strong>decide</strong> to keep going when prediction is uncertain—and then push the horizon further.</p> <h3 id="closing">Closing</h3> <p>If this sounds like it was written under the influence of <em>Interstellar</em> and a stack of RL papers, that’s because it was<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup>. Maybe it won’t make perfect sense to me later. But today it does, and that’s reason enough to hit “publish.”</p> <hr/> <h3 id="notes--references">Notes &amp; References</h3> <hr/> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1" role="doc-endnote"> <p>These motivations all surface in <em>Interstellar</em> in different forms-love, ambition, fear, isolation-guiding choices across uncertain frontiers. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2" role="doc-endnote"> <p>“Researchers vs. engineers” debate. <em><a href="https://x.com/elonmusk/status/1950254103474446728">Musk.</a></em> <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:3" role="doc-endnote"> <p>Author’s note: written during a phase of deep RL study and a fresh <em>Interstellar</em> rewatch. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name>Siddharth</name></author><category term="Exploration"/><category term="Philosophy"/><category term="AI"/><category term="Reinforcement-Learning"/><summary type="html"><![CDATA[I don’t post often, but after rambling in my editor and fresh off a rewatch of Interstellar, I felt compelled to share this. This isn’t a film review. It’s a reflection on a question that got stuck in my head as the credits rolled:]]></summary></entry><entry><title type="html">Life, Learning &amp;amp; LLMs</title><link href="https://siddharth7113.github.io/blog/2024/life-learning-llms/" rel="alternate" type="text/html" title="Life, Learning &amp;amp; LLMs"/><published>2024-10-23T00:00:00+00:00</published><updated>2024-10-23T00:00:00+00:00</updated><id>https://siddharth7113.github.io/blog/2024/life-learning-llms</id><content type="html" xml:base="https://siddharth7113.github.io/blog/2024/life-learning-llms/"><![CDATA[<h1 id="introduction">Introduction</h1> <p>I recently started the third year of my CS degree and realized something significant: I am part of the first generation of college students who have access to a whole new paradigm of learning with AI. Up to this point, everything I heard about AI was theoretical. The most significant anecdote in my memory about AI stems from my 6th or 7th-grade English book, an Isaac Asimov story <a href="#1">[1]</a>.</p> <p>Returning to the point, I wanted to talk about how AI has subtly changed my daily life. To be clear, I’m not claiming it has revolutionized everything, but I’ve noticed some changes in my habits—some for better, some for worse.</p> <p>Two of the most significant use cases for AI in my life as a college student are writing/learning and coding. There are others too, but these have had a profound impact on me as a person.</p> <h1 id="daily-writing-with-llms">Daily Writing with LLMs</h1> <p>When I started using Language Learning Models (LLMs), I was surprised not by their ability to write but by their ability to adapt to different writing styles. This opened many doors—some good, like no longer having to spend too much time writing applications or emails for mundane tasks, and some bad, like easily slacking through my creative classes at college. I no longer found writing technical essays or homework that required hours of research to be tedious tasks since AI could generate them for me within seconds. Although sometimes it got me into trouble with cited sources, I soon learned that tweaking my prompts could help with that. But the million-dollar question is:</p> <h2 id="did-it-make-my-writing-worse-or-better">Did it make my writing worse or better?</h2> <p>In high school, we were often asked to write answers to literature questions spontaneously. This exercise was done so frequently that I feel it genuinely improved my ability to articulate thoughts. Certainly, I might not be a great writer, but I can at least express myself well. (It might be obvious at this point, but English is not my first language, though I’ve been learning it for the past 15 years, so I should be good by now.) So, I can’t say it has degraded my ability to write well, but it has certainly helped me express myself better (which, as you’ll see, isn’t necessarily the case for coding).</p> <p>AI has certainly made me lazier. When I receive an email or write something, I jot down a rough reply in Notepad and ask the AI to improve it later. After some prompting, I get satisfactory results. For example, take this blog—I’m pretty sure that before publishing, I’ll pass it through AI to improve the tone and correct grammatical errors. Wait! Now that I think about it, I’ll also attach my manually written draft so you can compare my writing style with the published one <a href="#2">[2]</a>. It’s certainly not a perfect metric, but it’s something!</p> <p>At the same time, it has various advantages for me. Now, when I apply for internships, I no longer have to write my Statements of Purpose (SOPs) from scratch multiple times. I can just <strong>prompt-bomb</strong> <a href="#3">[3]</a> it with all the info about the internship, my goals, my resume, and it whips up a great first draft. From there, with a bit of prompting, things become a lot easier. What would have taken me days to write can be completed in a matter of hours. So that’s definitely going into the plus column.</p> <p>Now, coming to the second and most controversial use case (sometimes it keeps me up at night!):</p> <h1 id="coding-with-llms">Coding with LLMs</h1> <p>If you’re reading this blog, there’s a great chance you’ve used AI for coding. Before we dive into this, a caution: I used to be a big believer in AI boosting your learning—I still am—but for coding purposes, I’m not so sure anymore. Before we go any further, we need to clarify something, including “What does being good at coding mean?” For the purpose of this blog (and for me personally), it means being able to convert your thoughts and ideas into a practical software application with a reasonable understanding of its workings. Of course, you can disagree with me—I hope you do :)</p> <h2 id="llm-learning-curse">LLM Learning Curse</h2> <p>Now that we’ve defined it, let’s talk about how AI has shaped me. When I entered college, I was given the same advice that millions of freshmen receive every year: learn the theory, practice, implement, and if you get stuck, “Google it, use Stack Overflow, refer to documentation, etc.” But as soon as AI arrived (ChatGPT in November 2022), things changed a lot. Unlike math, AI was good at coding (it could generate code for whatever I wanted it to do), and suddenly, most of my tasks were being outsourced to it. Mind you, it’s not that I wasn’t doing or trying my homework, but when I got stuck or didn’t know how to start, I framed the problem to AI, and voilà—a working answer was right in front of me.</p> <p>While on the surface it might not seem like a huge problem, let’s take an example: my OOP course. I read and implemented all the examples from my course book, but when someone asked me to write an example problem from scratch, I was blank. And here’s where things diverge from traditional learning. Without AI, your option was to Google it and hope to find the exact answer or go through the text again to gain a better understanding. But with AI, you don’t need to do all this; just give it the problem or your thoughts, and it customizes the answer to your needs. I was able to understand it, so it felt like I satisfied all the criteria: I could convert my thoughts to code, I had a reasonable understanding of it, and it worked! So, I thought I was getting good at coding.</p> <p>At first glance, this might seem obvious, and you might be thinking, “You’re not actually coding; you’re just using AI.” But hear me out—it’s not that simple. It’s not like I didn’t understand the concept; I knew when to use inheritance; I just wasn’t able to translate it into code. I used a tool to do so. I told it what I wanted to do; it did it for me; I read it, understood it, and implemented it. While this gave me some sense of confidence and understanding, it took something very important from me, which I realized very late: my knowledge of what not to do. In traditional learning, you go through lots of sites, lots of trial and error, and in the process, you learn what not to do. This is something I missed out on with AI.</p> <h2 id="the-good-part-of-coding-with-ai">The Good Part of Coding with AI</h2> <p>It’s not all gloomy and sad. I mean, at this point, it’s fairly obvious I should stop using AI for coding; it would solve all my problems. But consider the benefits it brought me. To give context, I’m someone who easily gets intimidated by things, especially in tech. If I read something once or twice and didn’t understand, I would think I lacked the prerequisite knowledge (which is only somewhat true in CS—that’s a topic for another day). This mindset would have stopped me from learning a lot of things, but with AI, the possibilities were limitless. I wanted to learn about AI in my first semester, but seeing all the math terms would have deterred me. But with LLMs, I was able to perform MNIST classification in Python with only a high-level understanding of things. Sure, this might not seem like a big deal, but think from the perspective of an 18-year-old who recently learned loops in Python—this was huge.</p> <p>But if you notice, I missed a step in becoming good at coding: I didn’t have a reasonable understanding. To overcome this, I found a loophole. I started learning about libraries like scikit-learn, PyTorch, and began looking into the APIs being used, and soon enough, I started to understand what was happening in the code. So, in a way, I started doing reverse learning. I first converted my idea into code and then learned how and what was happening in my code. This does satisfy the criteria of “reasonable understanding,” and soon enough, I was able to do all kinds of things. I was able to run before I could walk well, but I didn’t realize I was using a walker <a href="#4">[4]</a> to run for a long time. I call it the “Curse of AI”: <strong>I can understand code, but I can’t write it.</strong></p> <p>It enables me to do a lot of things, like fine-tuning a TTS model without having to learn what fine-tuning is. With AI, I felt the sky was the limit (note: with AI, I use docs and other methods, but instead of reading them myself, I <strong>prompt-bomb</strong> <a href="#3">[3]</a> them into AI to solve the problem, and most of the time, it works). So now I’m in this weird place where I can code a lot of things with reasonable understanding and at the same time, I cannot do this at all.</p> <h1 id="solution">Solution?</h1> <p>When I look at top developers and the OG anime-profile-picture developers, I find myself strangely disconnected and wonder, would I ever be able to do that? Sometimes I think as long as I use AI, I will always have this imposter syndrome. One obvious solution would be to stop using AI completely for coding, but that feels like trying to put a secret back into the bag.</p> <p>Recently, Andrej Karpathy tweeted this</p> <div class="jekyll-twitter-plugin"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Programming is changing so fast... I&#39;m trying VS Code Cursor + Sonnet 3.5 instead of GitHub Copilot again and I think it&#39;s now a net win. Just empirically, over the last few days most of my &quot;programming&quot; is now writing English (prompting and then reviewing and editing the…</p>&mdash; Andrej Karpathy (@karpathy) <a href="https://twitter.com/karpathy/status/1827143768459637073?ref_src=twsrc%5Etfw">August 24, 2024</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> <p>, and it made me think that now this is the new normal. It’s just that I never got the chance to explore the “old” techniques.</p> <p>The truth is I am still looking for the <strong>middle ground.</strong></p> <p>This is my first time writing a blog</p> <p>. Please leave feedback, thoughts, and criticism—I’d love to hear from you on <a href="https://x.com/Sid_899">X/Twitter</a>.</p> <hr/> <h3 id="references">References</h3> <ol> <li><a href="https://en.wikipedia.org/wiki/The_Fun_They_Had">The Fun They Had</a></li> <li><a href="https://www.notion.so/Original-Draft-128a0da4ab5080148c7cf337b788a530?pvs=21">Original Draft</a></li> <li>I have coined this term, hoping it catches on!</li> <li><a href="https://en.wikipedia.org/wiki/Baby_walker">Baby Walker</a></li> </ol> <hr/>]]></content><author><name>Siddharth</name></author><category term="AI"/><category term="Learning"/><category term="Coding"/><category term="LLMs"/><summary type="html"><![CDATA[Introduction]]></summary></entry></feed>